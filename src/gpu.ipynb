{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3482c8c2",
   "metadata": {},
   "source": [
    "# Empirical Analysis of Early Stopping and Learning Rate Scheduling for Deep Learning on Resource-Constrained Hardware\n",
    "\n",
    "This file serves as the codebase for doing the experimentations done in the paper entitled as ***\"Empirical Analysis of Early Stopping and Learning Rate Scheduling for Deep Learning on Resource-Constrained Hardware\"***.\n",
    "\n",
    "This specific file serves as the GPU testing notebook, separating it from the [Colab](./colab.ipynb) and [CPU](./cpu.ipynb) experimentation notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b584f9",
   "metadata": {},
   "source": [
    "**Purpose:**\n",
    "\n",
    "To provide an empirical analysis on how specific training optimizations perform under resource-constrained hardwares. This explores consumer-grade hardware typically accessible to students and researchers with limited resources, allowing a large part of the Deep Learning community to be able to run potentially more complex tasks on such readily available devices."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817aee0c",
   "metadata": {},
   "source": [
    "## Imports\n",
    "\n",
    "All needed libraries will be imported here.\n",
    "\n",
    "Unless conditional, all imports must be done in this section to prevent workspace cluttering. Imports are sorted in an ascending manner, starting from \"a\" to \"Z\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ce006e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from tensorflow.keras import layers, Input\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from typing import Any, Dict, Union\n",
    "import datetime\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import psutil\n",
    "import random\n",
    "import seaborn as sns\n",
    "import subprocess as sp\n",
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "try:\n",
    "    import GPUtil\n",
    "    gputil_exist = True\n",
    "except ImportError:\n",
    "    gputil_exist = False\n",
    "\n",
    "if (os.name == 'nt'):\n",
    "    import wmi\n",
    "    import winsound\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba261b75",
   "metadata": {},
   "source": [
    "## Data and Variables\n",
    "\n",
    "Sets all the global data and variables here.\n",
    "\n",
    "Global variables will be defined and instantiated in this section, preventing a confusing clutter down the line and allowing readability when revisions are needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaaca442",
   "metadata": {},
   "source": [
    "### Instantiations\n",
    "\n",
    "Instantiations of objects will be done here, preventing mixture of variable preview and definition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e985d7e5",
   "metadata": {},
   "source": [
    "#### Variables\n",
    "\n",
    "Variable instantiations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e37ef9b",
   "metadata": {},
   "source": [
    "##### Dataset and Model Variables\n",
    "\n",
    "All dataset and model related variables are defined here, separated from the logger related ones, allowing cohesion in the already chaotic ~~world~~ notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "731baf16",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data = {\n",
    "    'class_names': [\n",
    "\t\t'airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "\t\t'dog', 'frog', 'horse', 'ship', 'truck'\n",
    "    ],\n",
    "\t'train': {\n",
    "\t\t'x': None,\n",
    "\t\t'y': None,\n",
    "\t},\n",
    "\t'test': {\n",
    "\t\t'x': None,\n",
    "\t\t'y': None,\n",
    "\t},\n",
    "    'val': None,\n",
    "}\n",
    "(data['train']['x'], data['train']['y']), (data['test']['x'], data['test']['y']) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(\n",
    "        monitor = 'val_loss',\n",
    "        patience = 10,\n",
    "        verbose = 2,\n",
    "        restore_best_weights = True\n",
    "    ),\n",
    "    # ReduceLROnPlateau(\n",
    "    #     monitor = 'val_loss',\n",
    "    #     factor = 0.5,\n",
    "    #     patience = 5,\n",
    "    #     verbose = 2,\n",
    "    #     min_lr = 1e-6\n",
    "    # )\n",
    "]\n",
    "\n",
    "save_plots = True\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da8bb6a",
   "metadata": {},
   "source": [
    "##### Metrics related variables\n",
    "\n",
    "(Static) Variables that will be used by the metric logger. Some variables are localized to the country where the researcher is based.\n",
    "\n",
    "When recreating the experiment, feel free to modify the values of the following variables to match your location's costs:\n",
    "\n",
    "- `local_currency_name`: The name of your local currency *(i.e.: Philippine Peso -> `\"peso\"`)*\n",
    "- `to_usd_conversion`: The cost of your location's currency to USD.\n",
    "- `cost_per_kwh_local`: The killowatt/hour cost in your location. Use local currency values.\n",
    "\n",
    "Some other variables are also changeable to allow the researcher(s) to easily update their values such as the `cpu_tdp`:\n",
    "\n",
    "- `platform`: The platform on where the experiment was done. In the researcher's case, it is `\"RTX 3050 Ti Laptop\"`.\n",
    "- `cpu_tdp`: The CPU's themal design power (TDP) in watts. This is different for every CPU.\n",
    "- `room_temp`: The current room temperature of where the hardware is located while the experiment is being conducted.\n",
    "\n",
    "These last two variables are for the logging:\n",
    "\n",
    "- `prefix`: The location on where the log will be saved. Could be a relative or an absolute path.\n",
    "- `file_name`: The name of the log file. Must be a JSON format... but realistically, it could be any file extension. In the end, it'll still log it in JSON. ~~LMAO~~"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824a70e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The local currency used by the researcher (PHP -> peso)\n",
    "local_currency_name = \"peso\"\n",
    "\"\"\"\n",
    "Defines the name of the local currency used by the researcher. This is to simplify\n",
    "and allow flexible changes to the local currency when someone wishes to recreate the\n",
    "experiment in a different country or region.\n",
    "\"\"\"\n",
    "\n",
    "# As of May 30, 2025 (PHP -> USD)\n",
    "to_usd_conversion = 0.018\n",
    "\"\"\"\n",
    "Defines the conversion rate of the local currency to US Dollar.\n",
    "\"\"\"\n",
    "\n",
    "# kwh in local currency (in this case, PHP)\n",
    "cost_per_kwh_local = 13.01\n",
    "\"\"\"\n",
    "A fixed cost per kilowatt-hour in the local currency; the currency used by the country where\n",
    "the researcher is based.\n",
    "\"\"\"\n",
    "\n",
    "# kwh in US Dollar\n",
    "cost_per_kwh_usd = cost_per_kwh_local * to_usd_conversion\n",
    "\"\"\"\n",
    "A dollar conversion of the cost per kilowatt-hour from the local currency.\n",
    "\"\"\"\n",
    "\n",
    "platform = \"RTX 3050 Ti Laptop\"\n",
    "\"\"\"\n",
    "Defines the platform used for the experiment.\n",
    "\"\"\"\n",
    "\n",
    "cpu_tdp = 45\n",
    "\"\"\"\n",
    "Defines the thermal design power (TDP) of the CPU in watts.\n",
    "\"\"\"\n",
    "\n",
    "env_temp = 19\n",
    "\"\"\"\n",
    "Manual temperature setting for the time the experiment was conducted. The researcher used the\n",
    "location's temperature based on the weather station at the time of the experiment. However,\n",
    "it would be better to use a temperature sensor to get the temperature of the room where the\n",
    "experiment was conducted for a more accurate result.\n",
    "\n",
    "Temperature is in degrees Celsius.\n",
    "\"\"\"\n",
    "\n",
    "prefix = \"./../out/gpu\"\n",
    "\"\"\"\n",
    "Defines the output directory for the training metrics.\n",
    "\"\"\"\n",
    "\n",
    "file_name = lambda postfix=None: f\"{prefix}/training_metrics{f'_{postfix}' if postfix is not None and len(postfix) > 0 else ''}.log\"\n",
    "\"\"\"\n",
    "Defines the file name for the training metrics.\n",
    "\"\"\"\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38e0f14",
   "metadata": {},
   "source": [
    "#### Functions\n",
    "\n",
    "Function creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c995bf8",
   "metadata": {},
   "source": [
    "##### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7ce9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def showImg(input, title = None, axis = False):\n",
    "    \"\"\"\n",
    "    Displays an image.\n",
    "\n",
    "    :param input: The image to display.\n",
    "    :type input: numpy.ndarray\n",
    "    \n",
    "    :param title: Title of the image.\n",
    "    :type title: str\n",
    "\n",
    "    :param axis: Whether to show the axis or not.\n",
    "    :type axis: bool\n",
    "    \"\"\"\n",
    "    plt.imshow(input)\n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    if not axis:\n",
    "        plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a86cdc4",
   "metadata": {},
   "source": [
    "##### Logger Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d26b712",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_metrics(metrics: Dict[str, Any], platform: str, lr_strategy: str):\n",
    "    \"\"\"\n",
    "    Logs the training metrics to a JSON file, including the platform (manual input) and\n",
    "    learning rate strategy (manual input). Some metrics are fixed and are defined in the\n",
    "    global variables section (under `Metrics related variables`).\n",
    "\n",
    "    The metrics that are logged include:\n",
    "    - `epoch`: The epoch in which the metrics were recorded.\n",
    "    - `loss`: The loss value at the end of the epoch.\n",
    "    - `accuracy`: The accuracy value at the end of the epoch.\n",
    "    - `training_time_hours`: The total training time in hours.\n",
    "    - `platform`: The platform on which the training was performed (manual input).\n",
    "    - `lr_strategy`: The learning rate strategy used during training (manual input).\n",
    "    - `room_temp`: The room temperature during training (under `Metrics related variables`).\n",
    "    - `cpu_percent`: The CPU usage (in percentage) during training.\n",
    "    - `cpu_power`: The CPU power consumption (in watts) during training.\n",
    "    - `gpu_load`: The GPU load (in percentage) during training.\n",
    "    - `gpu_power`: The GPU power consumption (in watts) during training.\n",
    "    - `accuracy_per_watt`: The accuracy per watt, calculated as `accuracy / (gpu_power + cpu_power)`.\n",
    "    - `convergence_per_local_currency`: The convergence per local currency, calculated as `accuracy / ((gpu_power + cpu_power) * training_time_hours * cost_per_kwh_local_currency)`.\n",
    "    - `convergence_per_dollar`: The convergence per dollar, calculated as `accuracy / ((gpu_power + cpu_power) * training_time_hours * cost_per_kwh_usd)`.\n",
    "    - `timestamp`: The timestamp when the metrics were logged.\n",
    "\n",
    "    **NOTE:** The `..._local_currency` refers to the local currency used by the researcher, which is defined in the global variables section.\n",
    "    This may be changed to a different currency to reflect the local currency of the researcher.\n",
    "    In the original experiment, the local currency is the Philippine peso (PHP). The variable is named `cost_per_kwh_local` so that it is easy\n",
    "    to understand that this could be changed easily into other local currency anyone wishes to use.\n",
    "\n",
    "    :param metrics: The training metrics to log.\n",
    "    :type metrics: dict\n",
    "\n",
    "    :param platform: The platform on which the training was performed.\n",
    "    :type platform: str\n",
    "\n",
    "    :param lr_strategy: The learning rate strategy used during training.\n",
    "    :type lr_strategy: str\n",
    "    \"\"\"\n",
    "    timestamp = time.strftime(\"%Y-%m-%d %H:%M:%S\", time.localtime())\n",
    "\n",
    "    # Add new fields to the metrics dictionary\n",
    "    metrics['platform'] = platform\n",
    "    metrics['lr_strategy'] = lr_strategy\n",
    "    metrics['env_temp'] = env_temp\n",
    "\n",
    "    get_cpu_metrics(metrics)\n",
    "    get_gpu_metrics(metrics)\n",
    "\n",
    "    # Other metrics\n",
    "    effective_power = {\n",
    "        \"cpu\": metrics.get(\"cpu_power\", 0),\n",
    "        \"gpu\": metrics.get(\"gpu_power\", 0)\n",
    "    }\n",
    "    total_power = effective_power[\"cpu\"] + effective_power[\"gpu\"]\n",
    "\n",
    "    ## Accuracy per watt\n",
    "    metrics['accuracy_per_watt'] = metrics['accuracy'] / total_power if total_power > 0 else \"N/A (No power consumption)\"\n",
    "\n",
    "    # Covergence per peso and dollar\n",
    "    training_time_hours = metrics.get(\"training_time_hours\", 0)\n",
    "    total_cost_local = (total_power / 1000) * training_time_hours * cost_per_kwh_local\n",
    "\n",
    "    metrics[f\"convergence_per_{local_currency_name}\"] = metrics.get(\"accuracy\", 0) / total_cost_local if total_cost_local > 0 else 0\n",
    "    metrics[\"convergence_per_dollar\"] = metrics.get(\"accuracy\", 0) / (total_cost_local * to_usd_conversion) if total_cost_local > 0 else 0\n",
    "\n",
    "    metrics['timestamp'] = timestamp\n",
    "\n",
    "    with open(file_name(), \"a\") as log:\n",
    "        log.write(json.dumps(metrics) + \"\\n\")\n",
    "\n",
    "    print(metrics)\n",
    "\n",
    "def get_cpu_metrics(metrics: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Gets the CPU metrics and adds them to the metrics dictionary.\n",
    "\n",
    "    :param metrics: The training metrics to log.\n",
    "    :type metrics: dict\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if (os.name == 'nt'):\n",
    "            c = wmi.WMI()\n",
    "\n",
    "            # cpu_tdp is defined at the \"Metrics related variables\" section.\n",
    "            metrics[\"cpu_percent\"] = c.Win32_Processor()[0].LoadPercentage\n",
    "            metrics[\"cpu_power\"] = (metrics[\"cpu_percent\"] / 100) * cpu_tdp\n",
    "        else:\n",
    "            metrics[\"cpu_percent\"] = psutil.cpu_percent(interval = None)\n",
    "\n",
    "            # The current method of estimating CPU power is not available on Linux/macOS.\n",
    "            # Please recode this part if you want to use a different method.\n",
    "            metrics[\"cpu_power\"] = \"N/A (OS now Windows; TDP estimate not available)\"\n",
    "            print(\"Note: CPU power estimation via TDP is currently configured for Windows. For Linux/macOS, direct wattage might require other libraries/tools.\")\n",
    "    except Exception as e:\n",
    "        metrics['cpu_percent'] = \"Error\"\n",
    "        metrics['cpu_power'] = \"Error\"\n",
    "        print(f\"Error getting CPU metrics: {e}\")\n",
    "\n",
    "def get_gpu_metrics(metrics: Dict[str, Any]):\n",
    "    \"\"\"\n",
    "    Gets the GPU metrics and adds them to the metrics dictionary.\n",
    "\n",
    "    :param metrics: The training metrics to log.\n",
    "    :type metrics: dict\n",
    "    \"\"\"\n",
    "    metrics[\"gpu_load\"] = \"N/A\"\n",
    "    metrics[\"gpu_power\"] = \"N/A\"\n",
    "\n",
    "    if gputil_exist:\n",
    "        try:\n",
    "            gpus = GPUtil.getGPUs()\n",
    "\n",
    "            if gpus:\n",
    "                metrics[\"gpu_load\"] = gpus[0].load * 100  # Convert to percentage\n",
    "\n",
    "                try:\n",
    "                    # Attempt to get GPU power using nvidia-smi\n",
    "                    command = \"nvidia-smi --query-gpu=power.draw --format=csv,noheader,nounits\"\n",
    "                    output = sp.check_output(command, shell=True).decode('utf-8').strip()\n",
    "                    metrics[\"gpu_power\"] = float(output) if output else 0.0\n",
    "                except (sp.CalledProcessError, FileNotFoundError):\n",
    "                    metrics[\"gpu_power\"] = \"N/A\"\n",
    "                except Exception:\n",
    "                    metrics[\"gpu_power\"] = \"Error\"\n",
    "        except Exception as e:\n",
    "            metrics[\"gpu_load\"] = \"Error\" if metrics[\"gpu_load\"] is None else metrics[\"gpu_load\"]\n",
    "            metrics[\"gpu_power\"] = \"Error\" if metrics[\"gpu_power\"] is None else metrics[\"gpu_power\"]\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053d28c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom callback class to log the metrics real-time during training.\n",
    "class MetricLoggerCallback(Callback):\n",
    "    \"\"\"\n",
    "    A custom callback to log training metrics and system performance during the training process,\n",
    "    allowing the researcher to monitor crucial statistics for the experiment.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, platform: str, lr_strategy: str, start_time: Union[float, None] = None):\n",
    "        super().__init__()\n",
    "\n",
    "        self.platform = platform\n",
    "        self.lr_strategy = lr_strategy\n",
    "        self.start_time_session = start_time if start_time is not None else time.time()\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs = None):\n",
    "        \"\"\"\n",
    "        Called at the end of each epoch to log the metrics and system performance.\n",
    "        \n",
    "        :param epoch: The current epoch number.\n",
    "        :type epoch: int\n",
    "        \n",
    "        :param logs: A dictionary containing the metrics for the current epoch.\n",
    "        :type logs: dict\n",
    "        \"\"\"\n",
    "        logs = logs or {}\n",
    "\n",
    "        # Calculate cumulative training time up to this epoch\n",
    "        elapsed_time_seconds = time.time() - self.start_time_session\n",
    "        training_time_hours = elapsed_time_seconds / 3600\n",
    "\n",
    "        # Prepare metrics dictionary for the log_metrics function\n",
    "        epoch_metrics = {\n",
    "            \"epoch\": epoch + 1,  # Keras epochs are 0-indexed, so add 1 for logging\n",
    "            \"loss\": logs.get('loss'),\n",
    "            \"accuracy\": logs.get('accuracy'),\n",
    "            \"val_loss\": logs.get('val_loss'),\n",
    "            \"val_accuracy\": logs.get('val_accuracy'),\n",
    "            \"training_time_hours\": training_time_hours\n",
    "        }\n",
    "\n",
    "        log_metrics(\n",
    "            metrics = epoch_metrics,\n",
    "            lr_strategy = self.lr_strategy,\n",
    "            platform = self.platform\n",
    "        )\n",
    "\n",
    "None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9f0061",
   "metadata": {},
   "source": [
    "##### Model Related Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09ee9bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(x, filters, stride = 1):\n",
    "    \"\"\"\n",
    "    Defines a standard ResNet residual block with two convolutional layers.\n",
    "    Handles identity and projection shortcuts based on stride and filter changes.\n",
    "\n",
    "    :param x: Input tensor to the residual block.\n",
    "    :type x: tf.Tensor\n",
    "\n",
    "    :param filters: Number of filters for the convolutional layers within the block.\n",
    "    :type filters: int\n",
    "\n",
    "    :param stride: Number of pixels to skip when applying the convolutional layers.\n",
    "    :type stride: int\n",
    "\n",
    "    :return x: Output tensor after applying the residual block operations.\n",
    "    :rtype: tf.Tensor\n",
    "    \"\"\"\n",
    "    shortcut = x\n",
    "    \n",
    "    # Downsample if the stride is not 1 or if the number of filters in the shortcut does not match\n",
    "    if stride != 1 or shortcut.shape[-1] != filters:\n",
    "        shortcut = layers.Conv2D(filters, (1, 1), strides=stride, padding='valid', use_bias=False)(shortcut)\n",
    "        shortcut = layers.BatchNormalization()(shortcut)\n",
    "\n",
    "    # First convolutional layer in the residual path\n",
    "    x = layers.Conv2D(filters, (3, 3), strides=stride, padding='same', use_bias=False)(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x) # ReLU after BN as per diagram for first conv\n",
    "\n",
    "    # Second convolutional layer in the residual path\n",
    "    x = layers.Conv2D(filters, (3, 3), strides=1, padding='same', use_bias=False)(x) # Second conv always stride 1\n",
    "    x = layers.BatchNormalization()(x)\n",
    "\n",
    "    # Add the shortcut to the residual path output\n",
    "    x = layers.add([x, shortcut])\n",
    "    x = layers.ReLU()(x) # Final ReLU after addition for the block output\n",
    "    \n",
    "    return x\n",
    "\n",
    "def build_resnet18(input_shape:tuple = (32, 32, 3), num_classes:int = 10, model_name:str = \"ResNet18_CIFAR10_Functional\"):\n",
    "    \"\"\"\n",
    "    Builds the ResNet-18 model for CIFAR-10 classification using the Keras Functional API.\n",
    "\n",
    "    This implementation closely follows the provided ResNet-18 architecture diagram\n",
    "    (e.g., [resnet18_cifar10_diagram.png](./../resnet18_cifar10_diagram.png)) for CIFAR-10 specific configurations like initial\n",
    "    filter counts and inclusion of Dropout.\n",
    "    \"\"\"\n",
    "    input_tensor = Input(shape=input_shape)\n",
    "\n",
    "    # Initial Convolutional Layer\n",
    "    # Diagram: Conv2D (32, 3x3, stride=1)\n",
    "    x = layers.Conv2D(32, (3, 3), strides=(1, 1), padding='same', use_bias=False)(input_tensor)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.ReLU()(x)\n",
    "\n",
    "    # Stage 1: Two residual blocks with 64 filters, stride 1 (no downsampling)\n",
    "    # Diagram: Residual Block 1a (64->64), 1b (64->64)\n",
    "    x = residual_block(x, 64, stride=1) # Residual Block 1a\n",
    "    x = residual_block(x, 64, stride=1) # Residual Block 1b\n",
    "\n",
    "    # Stage 2: Two residual blocks with 128 filters, first block has stride 2 (downsampling)\n",
    "    # Diagram: Residual Block 2a (64->128, stride=2), 2b (128->128)\n",
    "    x = residual_block(x, 128, stride=2) # Residual Block 2a (downsamples spatial dims by 2)\n",
    "    x = residual_block(x, 128, stride=1) # Residual Block 2b\n",
    "\n",
    "    # Stage 3: Two residual blocks with 256 filters, first block has stride 2 (downsampling)\n",
    "    # Diagram: Residual Block 3a (128->256, stride=2), 3b (256->256)\n",
    "    x = residual_block(x, 256, stride=2) # Residual Block 3a (downsamples spatial dims by 2)\n",
    "    x = residual_block(x, 256, stride=1) # Residual Block 3b\n",
    "\n",
    "    # Stage 4: Two residual blocks with 512 filters, first block has stride 2 (downsampling)\n",
    "    # Diagram: Residual Block 4a (256->512, stride=2), 4b (512->512)\n",
    "    x = residual_block(x, 512, stride=2) # Residual Block 4a (downsamples spatial dims by 2)\n",
    "    x = residual_block(x, 512, stride=1) # Residual Block 4b\n",
    "\n",
    "    # Final Layers\n",
    "    # Diagram: AdaptiveAvgPool2D (4x4 -> 1x1) - GlobalAveragePooling2D is the Keras equivalent\n",
    "    x = layers.GlobalAveragePooling2D()(x) # Output shape will be (batch_size, 512)\n",
    "\n",
    "    # Diagram: Flatten (512,) - Redundant after GlobalAveragePooling2D, but included for explicit diagram steps\n",
    "    x = layers.Flatten()(x)\n",
    "\n",
    "    # Diagram: Dropout (p=0.5)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "\n",
    "    # Diagram: Dense (512 -> 10)\n",
    "    outputs = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    # Create the Keras Model\n",
    "    model = Model(inputs = input_tensor, outputs = outputs, name = model_name)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "583c5d14",
   "metadata": {},
   "source": [
    "#### Processes\n",
    "\n",
    "Some data processing like pixel normalization and such."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96a006f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility. Starts with 42 then increment per experiment.\n",
    "seed = 42\n",
    "\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb884308",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['train']['x'] = data['train']['x'].astype('float32') / 255.0\n",
    "data['test']['x'] = data['test']['x'].astype('float32') / 255.0\n",
    "\n",
    "data['train']['y'] = data['train']['y'].flatten()\n",
    "data['test']['y'] = data['test']['y'].flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2397c57f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_strats = \"\"\n",
    "\n",
    "for strat in callbacks:\n",
    "    if callbacks.index(strat) > 0:\n",
    "        lr_strats += \" & \"\n",
    "\n",
    "    lr_strats += strat.__class__.__name__\n",
    "\n",
    "callbacks.append(\n",
    "    MetricLoggerCallback(\n",
    "        platform = platform,\n",
    "        lr_strategy = lr_strats,\n",
    "        start_time = time.time()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1c9ae61",
   "metadata": {},
   "source": [
    "#### Preview\n",
    "\n",
    "Preview the created and instantiated variables and functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d1508f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train data shape: {data['train']['x'].shape}, Train labels shape: {data['train']['y'].shape}\")\n",
    "print(f\"Test data shape: {data['test']['x'].shape}, Test labels shape: {data['test']['y'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ce48ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = random.randint(0, len(data['train']['x']) - 1)\n",
    "showImg(data['train']['x'][target], title = f\"Label: {data['class_names'][data['train']['y'][target]]} ({data['train']['y'][target]})\", axis = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865adc56",
   "metadata": {},
   "source": [
    "## Process\n",
    "\n",
    "Here begins the process which includes data splitting and pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeda29fc",
   "metadata": {},
   "source": [
    "### Splitting the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb39c6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Already splitted..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a1326e",
   "metadata": {},
   "source": [
    "### Pre-Processing\n",
    "\n",
    "Image pre-processing, along with some image modification (skew, translate, etc.) are done here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc9a8d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Data\n",
    "data['train']['generator'] = (ImageDataGenerator(\n",
    "\trescale = 1./255,\n",
    "    rotation_range = 20,\n",
    "    width_shift_range = 0.2,\n",
    "    height_shift_range = 0.2,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True\n",
    ")).flow(\n",
    "\tdata['train']['x'],\n",
    "\tdata['train']['y'],\n",
    ")\n",
    "\n",
    "# Validation Data\n",
    "data['val'] = ImageDataGenerator(\n",
    "    rescale = 1./255\n",
    ").flow(\n",
    "    data['test']['x'],\n",
    "    data['test']['y'],\n",
    ")\n",
    "\n",
    "# Test Data\n",
    "data['test']['generator'] = (ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    ")).flow(\n",
    "\tdata['test']['x'],\n",
    "\tdata['test']['y'],\n",
    "    shuffle = False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2546ca3",
   "metadata": {},
   "source": [
    "### Creating the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e23c0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_resnet18()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48c4461f",
   "metadata": {},
   "source": [
    "### Compilation and Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec47e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(learning_rate = 1e-4), # 0.0001\n",
    "    loss = 'sparse_categorical_crossentropy',\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2f44a31",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "SPE = len(data['train']['x']) // batch_size\n",
    "VS = len(data['test']['x']) // batch_size\n",
    "\n",
    "print(f\"Steps per epoch: {SPE}, Validation steps: {VS} (batch size: {batch_size})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb423fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    data[\"train\"][\"generator\"],\n",
    "    steps_per_epoch = SPE,\n",
    "    epochs = 100,\n",
    "    validation_data = data[\"val\"],\n",
    "    validation_steps = VS,\n",
    "    callbacks = callbacks\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0812c322",
   "metadata": {},
   "source": [
    "## Model Metrics Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e1e485",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, accuracy = model.evaluate(\n",
    "    data[\"test\"][\"generator\"],\n",
    "    steps = VS,\n",
    "    verbose = 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be86d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(\n",
    "    data['test']['generator'],\n",
    "    steps = VS,\n",
    "    verbose = 1,\n",
    ")\n",
    "\n",
    "y_pred = np.argmax(y_pred, axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67c074e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(y_pred))\n",
    "\n",
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6829d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = []\n",
    "for _ in range(VS):\n",
    "    _, labels = next(data[\"test\"][\"generator\"])\n",
    "    \n",
    "    if labels.ndim > 1 and labels.shape[1] > 1:\n",
    "        labels = np.argmax(labels, axis=1)\n",
    "    y_true.extend(labels)\n",
    "\n",
    "y_true = np.array(y_true)\n",
    "\n",
    "if len(y_true) != len(y_pred):\n",
    "    min_len = min(len(y_true), len(y_pred))\n",
    "    y_true = y_true[:min_len]\n",
    "    y_pred = y_pred[:min_len]\n",
    "\n",
    "print(len(y_true))\n",
    "\n",
    "y_true.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e680ea",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f498609e",
   "metadata": {},
   "outputs": [],
   "source": [
    "unixTime = int(datetime.datetime.now().timestamp() * 1e6)\n",
    "\n",
    "plt.figure(figsize = (10, 6))\n",
    "plt.plot(history.history['accuracy'], color = 'blue', label = 'train')\n",
    "plt.plot(history.history['val_accuracy'], color = 'red', label = 'val')\n",
    "plt.plot(history.history['loss'], color = 'green', label = 'train loss')\n",
    "plt.plot(history.history['val_loss'], color = 'orange', label = 'val loss')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.title(f'Accuracy over epochs\\n{platform} - {lr_strats}\\n{data[\"train\"][\"generator\"].batch_size} batch size')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "if not os.path.exists(f\"{prefix}/accuracy\"):\n",
    "    os.makedirs(f\"{prefix}/accuracy\")\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig(f\"{prefix}/accuracy/{platform}-{unixTime}-{accuracy:.2f}%.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c81f94",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37428fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(\n",
    "    y_true,\n",
    "    y_pred\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot = True, fmt = 'd', cmap = 'Blues')\n",
    "\n",
    "plt.title(f'Confusion Matrix \\n{platform} - {lr_strats}\\n{data[\"train\"][\"generator\"].batch_size} batch size')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "\n",
    "if not os.path.exists(f\"{prefix}/confusion_matrix\"):\n",
    "    os.makedirs(f\"{prefix}/confusion_matrix\")\n",
    "\n",
    "if save_plots:\n",
    "    plt.savefig(f\"{prefix}/confusion_matrix/{platform}-{unixTime}-{accuracy:.2f}%.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ffca80",
   "metadata": {},
   "source": [
    "## Notification Sound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "004d854c",
   "metadata": {},
   "outputs": [],
   "source": [
    "alarm_iteration = 1000\n",
    "alarm_sound = \"notification.wav\"\n",
    "\n",
    "if (os.name == 'nt'):\n",
    "    for i in range(alarm_iteration):\n",
    "        delay = float(\"{0:.2f}\".format(random.uniform(0, 0.5)))\n",
    "        \n",
    "        if os.path.exists(alarm_sound):\n",
    "            winsound.PlaySound(alarm_sound, winsound.SND_FILENAME)\n",
    "            time.sleep(delay)\n",
    "        else:\n",
    "            winsound.Beep(1000, 500)\n",
    "            time.sleep(0.5)\n",
    "\n",
    "        print(f\"Alarm sound played {i + 1}/{alarm_iteration} times (delayed by {delay} second{'s' if delay > 0 else ''}).\")\n",
    "        winsound.PlaySound(None, winsound.SND_PURGE)\n",
    "else:\n",
    "    print(\"Training completed. Beep sound is not available on this OS.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
